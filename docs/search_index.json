[
["index.html", "Matemàtiques II Presentació", " Matemàtiques II The Matemàtiques II team 2020-01-16 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["tema-0-repas-de-la-distribucio-normal.html", "Tema 0 Repàs de la distribució normal 0.1 Propietats de la distribució normal 0.2 Amb R 0.3 Tipificació 0.4 Intervals de referència 0.5 El z-score", " Tema 0 Repàs de la distribució normal 0.1 Propietats de la distribució normal Una variable aleatòria contínua \\(X\\) és normal de paràmetres \\(\\mu\\) i \\(\\sigma\\), i ho indicarem escrivint \\(X\\sim N(\\mu,\\sigma)\\), quan la seva funció de densitat és Naturalment, no cal saber aquesta fórmula. El que cal saber és que: Una variable aleatòria normal \\(X\\) és contínua, i per tant \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\sim N(\\mu,\\sigma)\\), aleshores el seu valor esperat és \\(E(X)=\\mu\\) i la seva desviació típica és \\(\\sigma_X=\\sigma\\) Una variable aleatòria normal és típica (o estàndard) quan \\(\\mu=0\\) i \\(\\sigma=1\\); la indicarem usualment amb \\(Z\\). Per tant, si \\(Z\\sim N(0,1)\\), \\(E(Z)=0\\) i \\(\\sigma_Z=1\\). La gràfica de la densitat d’una variable aleatòria normal és la famosa campana de Gauss: La gràfica de la densitat d’una variable aleatòria normal és també la menys famosa gràfica del capell del gendarme: La distribució normal és una distribució teòrica, no la trobareu exacta en la pràctica. I malgrat el seu nom, no és més “normal” que les altres distribucions que estudiarem. La distribució normal és important perquè aproxima bé moltes distribucions reals, perquè: Moltes variables aleatòries que consisteixen a prendre \\(n\\) observacions independents d’una o diverses variables aleatòries i sumar-les, tenen distribució aproximadament normal quan \\(n\\) és gran, encara que les variables aleatòries de partida no ho siguin. Per exemple: Si \\(X\\) és una variable aleatòria binomial B(n,p), amb \\(n\\) gran, alehores \\(X\\) és aproximadament \\(N(np,\\sqrt{np(1-p)})\\), en el sentit que les dues funcions de densitat (salvant la diferència pel fet que la binomial és discreta i la normal contínua) són semblants: Si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\) i \\(\\lambda\\) és gran, aleshores \\(X\\) és aproximadament \\(N(\\lambda,\\sqrt{\\lambda})\\) Si \\(X\\sim N(\\mu,\\sigma)\\), la seva densitat \\(f_X\\) és simètrica respecte de \\(x=\\mu\\), és a dir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] i té el màxim en \\(x=\\mu\\). Diem aleshores que \\(\\mu\\) és la moda de \\(X\\). Recordem que no té sentit definir la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sigui màxim, perquè \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\). Es defineix llavors la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(f_X(x_0)\\) és màxim. En particular, si \\(Z\\sim N(0,1)\\), llavors \\(f_{Z}\\) és simètrica al voltant de \\(x=0\\), és a dir, \\(f_{Z}(-x)=f_{Z}(x)\\), i la moda de \\(Z\\) és 0. Si la \\(\\mu\\) creix, el màxim es desplaça a la dreta, i amb ell tota la corba. Si la \\(\\sigma\\) creix, la corba s’aplata: en augmentar la desviació típica, els valors s’allunyen més del valor mitjà. Vegem l’efecte combinat: Recordem que la funció de distribució \\(F_X(x)=P(X\\leqslant x)\\) és l’àrea compresa entre la corba definida per la densitat \\(y=f_X(x)\\) i l’eix d’abscisses a l’esquerra de \\(x\\). La simetria de \\(f_X\\) fa que les àrees a l’esquerra de \\(\\mu-x\\) i a la dreta de \\(\\mu+x\\) siguin iguals. És a dir, \\[ P(X\\leqslant\\mu-x) = P(X\\geqslant\\mu+x)=1-P(X\\leqslant\\mu+x) \\] En particular (prenent \\(x=0\\)) \\[ P(X\\leqslant\\mu)=1-P(X\\leqslant\\mu)\\Rightarrow P(X\\leqslant\\mu)=0.5, \\] i per tant: Si \\(X\\sim N(\\mu,\\sigma)\\), \\(\\mu\\) és també la mediana de \\(X\\). En particular, si \\(Z\\sim N(0,1)\\), les àrees a l’esquerra de \\(-z\\) i a la dreta de \\(z\\) són iguals, \\[ P(Z\\leqslant-z)=P(Z\\geqslant z)=1-P(Z\\leqslant z), \\] i per tant, la mediana de \\(Z\\) és 0. Indicarem amb \\(z_q\\) el \\(q\\)-quantil d’una variable normal estàndard \\(Z\\). És a dir, \\(z_q\\) és el valor tal que \\(P(Z\\leqslant z_q)=q\\). A banda del fet que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) és 0), hi ha dos quantils més de la normal estándard que heu de saber: \\(z_{0.95}=1.64\\), és a dir, \\(P(Z&lt;-1.64)=P(Z&gt;1.64)=0.05\\). \\(z_{0.975}=1.96\\), és a dir, \\(P(Z&lt;-1.96)=P(Z&gt;1.96)=0.025\\) Molt sovint el valor 1.96 de \\(z_{0.975}\\) s’aproxima per 2. 0.2 Amb R Per calcular probabilitats d’una variable normal emprant R, heu de recordar que la normal és norm. Per tant, si \\(X\\sim N(\\mu,\\sigma)\\): dnorm(x,mu,sigma) dóna el valor de la densitat \\(f_X(x)\\) pnorm(x,mu,sigma) dóna el valor de la distribució \\(F_X(x)=P(X\\leqslant x)\\) qnorm(q,mu,sigma) dóna el \\(q\\)-quantil de \\(X\\) rnorm(N,mu,sigma) dóna un vector de \\(n\\) nombres aleatoris generats amb aquesta distribució A la normal estàndard no és necessari entrar-hi \\(\\mu=0\\) i \\(\\sigma=1\\), són els valors per defecte d’aquests paràmetres. Vegem-ne alguns exemples: Si \\(X\\sim N(3,0.5)\\), què val \\(P(X\\leqslant 2)\\)? pnorm(2,3,0.5) ## [1] 0.02275013 Si \\(X\\sim N(0,1)\\), què val \\(P(-1\\leqslant X\\leqslant 1)\\)? Com que \\(P(-1\\leqslant X\\leqslant 1)=P(X\\leqslant 1)-P(X\\leqslant-1)\\), pnorm(1)-pnorm(-1) ## [1] 0.6826895 Què val el primer quartil d’una variable \\(N(3,0.5)\\)? qnorm(0.25,3,0.5) ## [1] 2.662755 0.3 Tipificació El resultat següent descriu el comportament de l’esperança \\(E\\) i la variància \\(\\sigma^2\\) d’una combinació lineal de variables aleatòries: Teorema . Siguin \\(Y_1,\\ldots,Y_n\\) variables aleatòries, \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), i \\(Y=Y=a_1Y_1+\\cdots+a_nY_n+b\\). Aleshores \\(E(Y)=a_1E(Y_1)+\\cdots+a_nE(Y_n)+b\\). Si \\(Y_1,\\ldots,Y_n\\) són independents, aleshores \\(\\sigma_Y^2=a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2\\) i per tant \\(\\sigma_Y=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}\\). Una combinació lineal de variables aleatòries normals independents torna a ser normal: Teorema . Si \\(Y_1,\\ldots,Y_n\\) son variables aleatòries normals independents, cada \\(Y_i\\sim N(\\mu_i,\\sigma_i)\\), i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), aleshores \\[ Y=a_1Y_1+\\cdots+a_nY_n+b \\] és una variable aleatòria \\(N(\\mu,\\sigma)\\) amb \\(\\mu\\) i \\(\\sigma\\) els que toquin pel teorema anterior: \\(\\mu=a_1\\mu_1+\\cdots+a_n\\mu_n+b\\) \\(\\sigma=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}\\) Com a cas particular, obtenim que una transformació afí d’una variable aleatòria normal torna a ser normal: Teorema . Si \\(X\\sim N(\\mu,\\sigma)\\) i \\(a,b\\in \\mathbb{R}\\), llavors \\(aX+b\\) també és normal, i en concret és \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, si \\(X\\sim N(\\mu,\\sigma)\\), llavors la seva tipificada \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] és \\(N(0,1)\\). Les probabilitats de la normal tipificada determinen les de la normal original, perquè si \\(X\\sim N(\\mu,\\sigma)\\), \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b) &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant\\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] 0.4 Intervals de referència Un interval de referència del q% per a una variable aleatòria \\(X\\) és un interval \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=\\frac{q}{100}. \\] És a dir, un interval de referència del q% per a \\(X\\) és un interval que conté els valors de \\(X\\) del q% de subjectes de la població on està definida. Els més comuns són els intervals de referència del 95%, que satisfan que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] i són els, que per exemple, us donen com a valors de referència a les analítiques: Quan es parla d’un interval de referència sense donar-ne la probabilitat, se sobreentén sempre que és l’interval de referència del 95%. Quan \\(X\\sim N(\\mu,\\sigma)\\), aquests intervals de referència es prenen sempre centrats en la mitjana \\(\\mu\\), és a dir, de la forma \\((\\mu-x,\\mu+x)\\). Per calcular-los fàcilment, podem emprar el resultat següent: Teorema . Si \\(X\\sim N(\\mu,\\sigma)\\), \\[ P\\big(\\mu- z_{(1+q)/2}\\cdot \\sigma\\leqslant X\\leqslant\\mu+ z_{(1+q)/2}\\cdot \\sigma\\big)=q \\] on, recordau, \\(z_{(1+q)/2}\\) indica el \\((1+q)/2\\)-quantil de \\(Z\\sim N(0,1)\\). En efecte: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant\\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-P(Z\\leqslant-{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-(1-P(Z\\leqslant{x}/{\\sigma}))=q\\\\ \\qquad \\mbox{(per la simetria de $f_Z$ al voltant de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant{x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant{x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] En particular, com que si \\(q=0.95\\), aleshores \\((1+q)/2=0.975\\) i llavors \\(z_{0.975}=1.96\\), i això sovint s’aproxima per 2, l’interval de referència del 95% per a \\(X\\sim N(\\mu,\\sigma)\\) és \\[ \\mu\\pm 1.96\\sigma \\] o simplement \\(\\mu\\pm 2\\sigma\\), per simplificar. Això diu, bàsicament, que si una població segueix una distribució normal \\(N(\\mu,\\sigma)\\), un 95% dels seus individus estan a distància como a màxim \\(2\\sigma\\) (“a dues sigmes”) de \\(\\mu\\). Exemple . Segons l’OMS, les alçades de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Vull trobar un interval d’alçades centrat en la mitjana que contengui les de la meitat de les europees de 18 anys. És, a dir, vull trobar l’interval de referència del 50% per a la variable aleatòria \\(X\\) definida per les alçades de les dones europees de 18 anys. Com que \\(X\\sim N(163.1,18.53)\\) i si \\(q=0.5\\), aleshores \\((1+q)/2=0.75\\), aquest interval és 163.1+qnorm(0.75)*18.53*c(-1,1) ## [1] 150.6017 175.5983 Arrodonint a cm, és l’interval [151, 176]. Per tant, la meitat de les dones europees de 18 anys fan entre 1.51 m i 1.76 m. Exemple . Quin és l’interval de referència per a les alçades de les dones europees de 18 anys? Com que sobreentenem que es tracta de l’interval de referència del 95%, és \\[ 163.1\\pm 1.96\\times 18.53\\Longrightarrow [127, 199] \\] o, aproximant l’1.96 per 2, \\[ 163.1\\pm 2\\times 18.53\\Longrightarrow [126, 200]. \\] 0.5 El z-score El z-score (o valor z, puntuació z) d’un valor \\(x_0\\) respecte d’una distribució \\(N(\\mu,\\sigma)\\) és \\[ \\frac{x_0-\\mu}{\\sigma}. \\] Com més gran és en valor absolut, més “rar” és \\(x_0\\); el signe ens diu si està per damunt o per davall del valor esperat \\(\\mu\\). Exemple . Recordau que, segons l’OMS, les altures de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin és el z-score d’una jugadora de bàsket de 18 anys que faci 191 cm? Serà: \\[ \\frac{191-163.1}{18.53}=1.5 \\] Això normalment es llegeix dient que aquesta alçada “està a 1.5 sigmes de l’alçada mitjana.” "],
["estimacio-puntual.html", "Tema 1 Estimació puntual 1.1 Definicions bàsiques 1.2 Mitjana mostral 1.3 Proporció mostral 1.4 Variància mostral 1.5 La t de Student 1.6 “Bons” estimadors 1.7 Estimació de poblacions", " Tema 1 Estimació puntual 1.1 Definicions bàsiques Una població és un conjunt d’individus o objectes sobre el que volem obtenir informació. Una mostra de mida \\(n\\) d’una població és simplement un conjunt de \\(n\\) individus (possiblement repetits) de la població. Una mostra aleatòria simple de mida \\(n\\) d’una població s’obté repetint \\(n\\) vegades, cada una de manera independent de les altres, el procés d’escollir equiprobablement un individu de la població; els individus triats es poden repetir. D’aquesta manera, totes les mostres possibles de \\(n\\) individus (possiblement repetits: en diem multiconjunts) tenen la mateixa probabilitat d’obtenir-se. Un estimador (puntual) o estadístic és una funció que aplicada a una mostra d’una població dóna un valor que ens permet estimar alguna cosa que vulguem saber de tota la població. Exemple 1.1 Si escollim a l’atzar, un rere l’altre i permetent que es repeteixin, 30 estudiants de la UIB i mesuram les seves alçades, obtenim una mostra aleatòria simple de mida 30 d’alçades de la població formada pels estudiants de la UIB. Si llavors calculam la mitjana aritmètica d’aquestes alçades amb l’objectiu d’estimar la mitjana de les alçades de tots els estudiants de la UIB, aquesta mitjana aritmètica és un estimador. Formalment: Una població és un conjunt on està definida una variable aleatòria \\(X\\). Una mostra aleatòria simple de mida \\(n\\) de la variable aleatòria \\(X\\) és un vector \\((X_1,\\ldots,X_n)\\) format per \\(n\\) còpies independents de \\(X\\). Una realització de la mostra aleatòria simple \\((X_1,\\ldots,X_n)\\) és un vector \\((x_1,\\ldots,x_n)\\) de valors presos per aquestes variables aleatòries. Un estimador és una variable aleatòria \\(f(X_1,\\ldots,X_n)\\) obtinguda aplicant una funció \\(f\\) a una mostra aleatòria simple \\(X_1,\\ldots,X_n\\). Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Com que és una variable aleatòria, té distribució (en diem la distribució mostral de l’estimador), esperança, desviació típica (en diem l’error estàndard, o típic, de l’estimador), etc. Exemple 1.2 Podem formalitzar l’Exemple 1.1 de la manera següent: Població: El conjunt dels estudiants de la UIB Variable aleatòria \\(X\\): Prenem un estudiant de la UIB i midam la seva alçada. Mostra aleatòria simple de mida 30: Un vector \\((X_1,\\ldots,X_{30})\\) format per 30 còpies independents de \\(X\\). Una realització d’aquesta mostra aleatòria simple: Un vector \\((x_1,\\ldots,x_{30})\\) obtingut repetint 30 vegades, de manera independent cada una de les altres, el procés d’escollir un estudiant de la UIB i midar-li l’alçada Estimador: La mitjana aritmètica que farem servir sobre aquesta mostra és \\[ \\overline{X}=\\frac{X_1+\\cdots+X_{30}}{30} \\] i sobre la realització concreta obtinguda pren el valor \\[ \\overline{x}=\\frac{x_1+\\cdots+x_{30}}{30} \\] A partir d’ara, quan no hi hagi necessitat de filar prim, cometrem l’abús de llenguatge de dir mostra aleatòria simple tant al vector de variables aleatòries \\((X_1,\\ldots,X_n)\\) com a una realització \\((x_1,\\ldots,x_n)\\in \\mathbb{R}^n\\); i hi ometrem els parèntesis. A la vida real, les mostres aleatòries se solen prendre sense repeticions (sense reposició). No són mostres aleatòries simples, però: Si la mida \\(N\\) de la població és MOLT més gran que la mida \\(n\\) de la mostra, els resultats per a mostres aleatòries simples valen (aproximadament) en aquest cas, perquè les repeticions són improbables i les variables aleatòries que formen la mostra són gairebé idèntiques i independents. Més en concret, si la població és MOLT gran (per exemple de 106 individus), excloure, per evitar repeticions, uns pocs individus ja escollits (per exemple, 9) no canvia gaire la probabilitat d’escollir un individu dels que queden: abans d’eliminar els 9 ja escollits, la probabilitat de triar un individu concret era \\(1/10^6=10^{-6}\\) i després d’excloure’ls és \\(1/999991=1.000009\\times 10^{-6}\\). Observau també que si prenem una mostra aleatòria sense repeticions d’una població molt gran, gairebé és com si hagués estat presa permetent repeticions, perquè per molt que les permetíssim, seria molt improbable que es donassin. Tornant al nostre exemple, si prenem una mostra aleatòria simple (permetent repeticions) de 10 individus d’una població de 106 individus, la probabilitat que escollim qualque individu més d’una vegada és \\[ 1-\\frac{10^6(10^6-1)\\cdots (10^6-9)}{(10^6)^{10}}=4.5\\times 10^{-5}. \\] Molt petita. Per tant, si ens trobam al davant d’una mostra aleatòria de 10 individus d’aquesta població escollida sense permetre repeticions, ens podem creure perfectament que l’hem obtinguda permetent repeticions i que simplement no n’hi ha hagut cap. Per tant: quan N és MOLT més gran que n, cometrem l’abús de llenguatge de també dir que tenim una mostra aleatòria simple. Quan \\(n\\) és relativament gran per comparació amb \\(N\\), ja és mal de creure que una mostra sense repeticions hagi estat escollida permetent-les. Per exemple, si prenem una mostra aleatòria simple (permetent repeticions) de 10 individus d’una població de 100 individus, la probabilitat que escollim qualque individu més d’una vegada és \\[ 1-\\frac{100\\cdot 99\\cdots 91}{100^{10}}=0.37. \\] Més d’una de cada 3 mostres aleatòries simples de 10 individus d’una població de 100 individus contenen qualque repetició, per tant no podem acceptar amb els ulls clucs que si no tenim cap repetició, les hàgim permeses. Exemple 1.3 Recordau que si una població té \\(N\\) individus, la probabilitat que una mostra aleatòria simple de mida \\(n\\) tingui tots els seus membres diferents és \\[ \\frac{N(N-1)\\cdots (N-n+1)}{N^n} \\] Per exemple, la UIB té uns 12000 estudiants. El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de \\(n\\) estudiants de la UIB, siguin tots diferents, en funció de \\(n\\): f=function(N,i){prod((N:(N-i+1))/N)} prob=sapply(1:200,f,N=1200) plot(1:200,prob,type=&quot;l&quot;,lwd=2,xlab=&quot;n&quot;,ylab=&quot;probabilitat&quot;, xaxp=c(0,200,20),yaxp=c(0,1,10)) El gràfic següent mostra la mida màxima \\(n\\) d’una mostra aleatòria simple extreta d’una població de mida \\(N\\) per què la probabilitat de repeticions sigui menor que 0.05, en funció de \\(N\\) h=function(n){max(which(sapply(1:(n/50),f,N=n)&gt;0.95))} fites=sapply(500+100*(0:150),h) plot(500+100*(0:150),fites,pch=20,xlab=&quot;N&quot;,ylab=&quot;n&quot;,xaxp=c(500,15500,30)) A la pràctica, en realitat (gairebé) mai no disposarem d’una mostra aleatòria. Ens haurem de conformar amb una mostra oportunista (o de conveniència}: la que poguem obtenir. Heu de tenir clar que, en principi, els resultats que donarem NO són vàlids en aquest cas, però si no tenim res millor… El que es fa aleshores és explicar amb detall com s’ha obtingut la mostra i descriure amb detall les seves característiques, a fi que altres investigadors puguin decidir si els individus “són típics” i podrien passar per una mostra aleatòria, i si poden extrapolar les estimacions al seu context. Per exemple, si per saber l’opinió dels estudiants de Biologia espanyols sobre un tema, ho deman als meus estudiants, serà una mostra clarament oportunista i caldrà llavors esbrinar si podria passar per una mostra aleatòria simple a efectes de l’estudi que vull portar a terme. Els estimadors tenen sempre sentit per a mostres en general, però gairebé tots els teoremes que estableixen les seves propietats són vertaders només sota determinades restriccions (mostra aleatòria simple, condicions extra sobre \\(X\\), …), per la qual cosa les seves conseqüències tan sols són segures sota aquestes restriccions. 1.2 Mitjana mostral La mitjana mostral \\(\\overline{X}\\) d’una mostra aleatòria de mida \\(n\\) d’una variable aleatòria \\(X\\) és simplement la seva mitjana artimètica. Formalment, la mitjana mostral és una variable aleatòria obtinguda prenent \\(n\\) còpies \\(X_1,\\ldots,X_n\\) de la variable aleatòria \\(X\\) i calculant \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] Com a conseqüència del Teorema ., tenim el següent: Teorema 1.1 Siguin \\(X\\) una variable aleatòria d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\), \\(X_1,\\ldots,X_n\\) una mostra aleatòria de \\(X\\) i \\(\\overline{X}\\) la seva mitjana mostral. Aleshores El valor esperat de \\(\\overline{X}\\) és \\(E(\\overline{X})=\\mu_X\\). Si la mostra aleatòria és simple, l’error estàndard o típic de \\(\\overline{X}\\) (la desviació típica de \\(\\overline{X}\\)) és \\(\\sigma(\\overline{X})={\\sigma_X}/{\\sqrt{n}}\\). Per tant: \\(\\overline{X}\\) és un estimador puntual de \\(\\mu_X\\). \\(E(\\overline{X})=\\mu_X\\) (esperam que la mitjana mostral doni \\(\\mu_X\\)) significa que si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a \\(\\mu_X\\). \\(\\sigma(\\overline{X})= \\sigma_X/\\sqrt{n}\\) indica que la variabilitat dels resultats de \\(\\overline{X}\\) creix amb la variabilitat de \\(X\\) i decreix amb la mida \\(n\\) de la mostra, tendint a 0 quan \\(n\\to\\infty\\) Exemple 1.4 El fitxer tests.txt que trobareu a l’Aula Digital conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. tests=scan(&quot;tests.txt&quot;) La seva mitjana és mean(tests) ## [1] 55.43243 Si en prenem una mostra aleatòria simple, per exemple de mida 40, la seva mitjana mostral no té perquè coincidir amb la mitjana poblacional: MAS=sample(tests,40,replace=TRUE) mean(MAS) ## [1] 53.5 Però si prenem moltes mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional: mitjanes=replicate(10^5,mean(sample(tests,40,replace=TRUE))) mean(mitjanes) ## [1] 55.4187 Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població: sd(mitjanes) ## [1] 3.384683 sd(tests) ## [1] 21.44044 sd(tests)/sqrt(40) ## [1] 3.390031 Recordau del Teorema . que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral d’una mostra aleatòria simple és una combinació lineal de variables aleatòries independents, obtenim el resultat següent: Teorema 1.2 Siguin \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Aleshores, \\[ \\overline{X}\\sim N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big) \\] i per tant \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}}\\sim N(0,1) \\] El Teorema Central del Límit diu que la conclusió del teorema anterior és aproximadament vertadera si la mida \\(n\\) de les mostres aleatòries simples és gran: Teorema 1.3 (Teorema Central del Límit) Sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple d’una variable aleatòria \\(X\\) qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Quan \\(n\\to \\infty\\), la distribució de probabilitats de \\(\\overline{X}\\) tendeix a la d’una \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big) \\] i per tant la distribució de probabilitats de \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}} \\] tendeix a la d’una variable normal estàndard \\(N(0,1)\\). Com us podeu imaginar, quan un resultat l’anomenen “Teorema Central” de qualque cosa és perquè és molt important. Exemple 1.5 Suposem que tenim una variable aleatòria \\(X\\) de mitjana \\(\\mu_X=3\\) i desviació típica \\(\\sigma_X=0.2\\) i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral \\(\\overline{X}\\) és aproximadament \\[ N\\Big(3,\\frac{0.2}{\\sqrt{100}}\\Big)=N(3,0.02) \\] Exemple 1.6 Tornem a la situació de l’Exemple 1.4. Teníem les notes guardades en un vector anomenat tests. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal. fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1] hist(tests,col=&quot;light blue&quot;,xlab=&quot;Notes dels tests&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de notes de tests&quot;) curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col=&quot;red&quot;,lwd=2,add=TRUE) A l’Exemple 1.4 també hem construit un vector anomenat mitjanes format per 105 mitjanes de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma: fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1] hist(mitjanes,col=&quot;light blue&quot;,xlab=&quot;Mitjanes&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de mitjanes&quot;) curve(fact.trans.m*dnorm(x,mean(mitjanes),sd(mitjanes)),col=&quot;red&quot;,lwd=2,add=TRUE) L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt. Exemple 1.7 L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm? Diguem \\(X\\) a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central de Límit, la mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de 100 alçades segueix una distribució aproximadament \\(N(115,25/\\sqrt{100})=N(115,2.5)\\). Llavors, la probabilitat que ens demanen és \\[ P(\\overline{X}&lt; 110) \\] que podem calcular amb round(pnorm(110,115,2.5),4) ## [1] 0.0228 Sigui ara \\(X_1,\\ldots, X_n\\) una mostra aleatòria sense reposició de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Si \\(n\\) és molt petit en relació a la mida \\(N\\) de la població, ja hem explicat que podem suposar que aquesta mostra aleatòria és simple i per tant tot funciona com fins ara; en particular, en aquest cas entendrem que els tres teoremes anteriors són vertaders. Si \\(n\\) és gran en relació a \\(N\\), aleshores el resultat per l’esperança segueix essent vertader (al Teorema 1.1.a no suposàvem que la mostra fos simple): \\[ E(\\overline{X})=\\mu_X \\] Però ara cal modificar la fórmula del Teorema 1.1.b per a la desviació típica, que ara és: \\[ \\sigma_{\\overline{X}}=\\frac{\\sigma_X}{\\sqrt{n}}\\cdot\\sqrt{\\frac{N-n}{N-1}} \\] A més, en aquest cas les conclusions dels Teoremes 1.2 i 1.3 no són certes, ni tan sols amb aquesta correcció de l’error típic. Al terme \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que apareix a la fórmula anterior li diuen el factor de població finita. Si us en recordau, aquest factor de població finita és el factor que passava de la desviació típica d’una distribució binomial a la d’una hipergeomètrica. En efecte: Si \\(X_B\\sim B(n,p)\\), \\(\\sigma^2_{X_B}=np(1-p)\\) i per tant \\(\\sigma_{X_B}=\\sqrt{np(1-p)}\\) Si \\(X_H\\sim H(A,B,n)\\), amb \\(A+B=N\\) i \\(p=A/N\\), \\[ \\begin{array}{rl} \\sigma^2_{X_H} &amp; \\displaystyle =\\dfrac{nAB}{(A+B)^2}\\cdot\\dfrac{A+B-n}{A+B-1} =n\\cdot\\frac{A}{N}\\cdot\\frac{N-A}{N}\\cdot\\dfrac{N-n}{N-1}\\\\ &amp; \\displaystyle = np(1-p)\\cdot \\dfrac{N-n}{N-1} \\end{array} \\] i per tant \\[ \\sigma_{X_H}=\\sqrt{np(1-p)}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}=\\sigma_{X_B}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}. \\] Exemple 1.8 Tornem a la situació dels Exemples 1.4 i 1.6. Què passa si prenem les mostres aleatòries de notes de tests sense reposició? Prenguem ara 105 mostres aleatòries sense reposició de notes de tests. mitjanes.norep=replicate(10^5,mean(sample(tests,40))) Un altre cop, la mitjana d’aquest vector de mitjanes hauria de ser propera a la mitjana de la població original, que era 55.43: round(mean(mitjanes.norep),2) ## [1] 55.42 Calculem ara la desviació típica d’aquest vector de mitjanes: round(sd(mitjanes.norep),2) ## [1] 3 Aquesta desviació típica no s’apropa a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres, que hem calculat abans i era 3.39. En canvi, pel que acabam d’explicar, la desviació típica d’aquest vector de mitjanes de mostres sense reposició hauria de ser molt propera a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres i tot multiplicat pel factor de població finita \\(\\sqrt{(N-n)/(N-1)}\\), on \\(N\\) és la mida de la població, és a dir, la longitud del vector tests, i \\(n\\) la mida de les mostres, 40. Vegem si és veritat: round((sd(tests)/sqrt(40))*sqrt((length(tests)-40)/(length(tests)-1)),2) ## [1] 3.01 1.3 Proporció mostral Sigui \\(X\\) una variable aleatòria Bernoulli amb probabilitat d’èxit (o proporció d’èxits) \\(p_X\\). Entendrem que \\(X\\) pren els valors 1 (èxit) o 0 (fracàs). Sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria de mida \\(n\\) de \\(X\\). Sigui \\(S=\\sum_{i=1}^n X_i\\) el nombre d’èxits observats en aquesta mostra aleatòria. Recordau que \\(E(X)=p_X\\) i \\(\\sigma_X=\\sqrt{p_X(1-p_X)}\\), i que si la mostra és aleatòria simple, aquesta \\(S\\) és una variable aleatòria binomial \\(B(n,p)\\). La proporció mostral d’èxits de la nostra mostra és \\[ \\widehat{p}_X=\\frac{S}{n}=\\frac{\\sum_{i=1}^n X_i}{n}. \\] Fixau-vos que \\(\\widehat{p}_X\\) és un cas particular de la mitjana mostral \\(\\overline{X}\\), per tant per a les proporcion mostrals val tot el que hem dit fins ara per a mitjanes mostrals: Teorema 1.4 Si \\(X\\) és una variable aleatòria Bernoulli amb probabilitat d’èxit \\(p_X\\), aleshores \\(E(\\widehat{p}_X)=p_X\\) Si la mostra aleatòria és simple, \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) Si la mostra aleatòria és sense reposició i \\(n\\) és relativament gran per comparació amb la mida de la població \\(N\\), \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{N-n}{N-1}} \\] Pel Teorema Central del Límit, quan prenem mostres aleatòries simples de mida \\(n\\) gran, la distribució de \\(\\widehat{p}_X\\) és aproximadament la d’una variable \\[ N\\left({p}_X,\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}\\right) \\] i per tant \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] és aproximadament \\(N(0,1)\\). Alguns comentaris: \\(E(\\widehat{p}_X)=p_X\\): Si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli \\(X\\) i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a \\(p_X\\). En particular, \\(\\widehat{p}_X\\) serveix per estimar \\(p_X\\) \\(\\sigma(\\widehat{p}_X)= \\sqrt{{p_X(1-p_X)}/{n}}\\): la variabilitat dels resultats de \\(\\widehat{p}_X\\) decreix amb \\(n\\) i tendeix a 0 quan \\(n\\to \\infty\\) \\(\\sqrt{{p_X(1-p_X)}/{n}}\\) és l’error típic de \\(\\widehat{p}_X\\). L’estimam amb l’error típic de l’estimació \\(\\sqrt{{\\widehat{p}_X(1-\\widehat{p}_X)}/{n}}\\). A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (4) del teorema anterior, i direm simplement que si \\(n\\) és gran, \\(\\widehat{p}_X\\) és normal. Però hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 1.9 Tornem una altra vegada a la situació dels Exemples 1.4 i 1.6. Vaig a traduir el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més): aprovs=rep(1,length(tests)) # Iniciam totes les notes a 1 aprovs[which(tests&lt;50)]=0 # Posam 0 on la nota del test és suspesa Aquest vector aprovs el podem entendre com una població de Bernoulli de probabilitat poblacional d’èxit (aprovat) \\(p_X\\). Les proporcions de suspesos i aprovats són: round(prop.table(table(aprovs)),4) ## aprovs ## 0 1 ## 0.4054 0.5946 Per tant, \\(p_X\\) és donada per: p_X=as.numeric(prop.table(table(aprovs))[2]) round(p_X,4) ## [1] 0.5946 Ara n’extreurem 105 mostres aleatòries simples de mida 40, en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior. set.seed(100) props.mostrals=replicate(10^5,mean(sample(aprovs,40,rep=TRUE))) La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats \\(p_X=0.5946\\). round(mean(props.mostrals),4) ## [1] 0.5942 Vegem ara la seva desviació típica: round(sd(props.mostrals),4) ## [1] 0.0774 Per teoria, sabem que això hauria de ser proper a \\(\\sqrt{p_X(1-p_X)/n}\\) round(sqrt(p_X*(1-p_X)/40),4) ## [1] 0.0776 I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal. Vegem-ho amb un histograma: fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1] hist(props.mostrals,col=&quot;light blue&quot;,xlab=&quot;Proporcions mostrals&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de proporcions&quot;) curve(fact.trans.p*dnorm(x,mean(props.mostrals),sd(props.mostrals)),col=&quot;red&quot;,lwd=2,add=TRUE) I això que la mida de les mostres, 40, no és especialment gran. Exemple 1.10 Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, un 66.67%. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 60% de dones). Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la següent pregunta: Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui superior al 66.67%? Una manera senzilla de respondre aquesta pregunta és aprofitar el Teorema Central del Límit, segons el qual la proporció mostral \\(\\widehat{p}_X\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb \\(\\mu=0.591\\) i \\[ \\sigma=\\sqrt{\\dfrac{0.591(1-0.591)}{60}}=0.0635 \\] Per tant, la probabilitat que \\(\\widehat{p}_X\\geqslant 0.6667\\) és (recordau, aproximadament) round(1-pnorm(0.6667,0.591,0.0635),4) ## [1] 0.1166 Naturalment, si tenim R o qualsevol altra manera de calcular probabilitats, també podem fer servir la distribució binomial per calcular aquesta probabilitat, i de fet és més correcte, ja que la probabilitat anterior ha emprat una aproximació de la distribució de \\(\\widehat{p}_X\\) i en canvi sabem que el nombre de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució binomial \\(B(60,0.591)\\) i com que el 66.67% de la pregunta en realitat representa 40 dones, la probabilitat exacta demanada és round(1-pbinom(39,60,0.591),4) ## [1] 0.1441 (Recordau que si \\(X\\) és una variable aleatòria discreta que pren valors enters, com ara la binomial, \\(P(X\\geqslant 40)=1-P(X\\leqslant 39)\\).) 1.4 Variància mostral Sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). La variància mostral d’aquesta mostra aleatòria simple és \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1} \\] La seva desviació típica mostral és \\[ \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] A més, de tant en tant també farem servir la variància i la desviació típica vertaderes: \\[ \\begin{array}{l} \\displaystyle S^2_{X}=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{(n-1)}{n}\\widetilde{S}^2_{X}\\\\ \\displaystyle S_X=+\\sqrt{S_X^2} \\end{array} \\] La variància vertadera admet la següent expressió senzilla: \\[ S^2_X=\\frac{\\sum_{i=1}^n X_{i}^2}{n}-\\overline{X}^2 \\] En efecte: \\[ \\begin{array}{l} \\displaystyle \\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{1}{n}\\sum_{i=1}^n (X_{i}^2-2\\overline{X}X_i+\\overline{X}^2)\\\\ \\displaystyle\\qquad = \\frac{1}{n}\\Big(\\sum_{i=1}^n X_{i}^2-2\\overline{X}\\sum_{i=1}^n X_{i}+n\\overline{X}^2\\Big)\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\frac{\\sum_{i=1}^n X_{i}}{n}+\\frac{n\\overline{X}^2}{n}\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\cdot\\overline{X} + \\overline{X}^2=\\frac{\\sum_{i=1}^n X_{i}^2}{n}- \\overline{X}^2 \\end{array} \\] Teorema 1.5 Si la variable aleatòria \\(X\\) és normal, aleshores \\(E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2\\) i la variable aleatòria \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] té distribució coneguda: \\(\\chi_{n-1}^2\\) (llegit ``khi quadrat amb \\(n-1\\) graus de llibertat). De la distribució \\(\\chi_n^2\\) (\\(\\chi\\): en català, khi; en castellà, ji; en anglès, chi, pronunciat xai), on \\(n\\) són els graus de llibertat, heu de saber que: Per definició, és la distribució de la suma dels quadrats de \\(n\\) variables aleatòries normals estàndard independents. És a dir, si \\(Z_{1},Z_{2},\\ldots, Z_{n}\\sim N(0,1)\\) són independents, la variable \\[ Z_{1}^{2}+Z_{2}^{2}+\\cdots +Z_{n}^{2} \\] té distribució \\(\\chi_n^2\\). La \\(n\\) és un paràmetre del que depèn la seva distribució. Amb R és chisq Si \\(X\\) és una variable aleatòria amb distribució \\(\\chi_n^2\\), aleshores \\(E(X)=n\\) i \\(\\sigma_X^2=2 n\\) Per a \\(n\\) petits, la distribució d’una \\(\\chi_{n}^2\\) presenta una cua a la dreta, i a mida que \\(n\\) creix, es va aproximant a una distribució normal \\(N(n,\\sqrt{2n})\\), com podeu veure als gràfics següents curve(dchisq(x,1),col=1,lwd=2,xlim=c(0,20),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.3),main=&quot;Algunes khi quadrat&quot;) curve(dchisq(x,2),col=2,lwd=2,add=TRUE) curve(dchisq(x,3),col=3,lwd=2,add=TRUE) curve(dchisq(x,4),col=4,lwd=2,add=TRUE) curve(dchisq(x,5),col=5,lwd=2,add=TRUE) curve(dchisq(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topright&quot;,col=1:6,lty=c(1,1), lwd=c(2,2),legend=paste(&quot;n=&quot;,c(1:5,10),sep=&quot;&quot;),cex=0.8) curve(dchisq(x,300),xlim=c(150,450),lwd=2,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;Khi quadrat vs Normal&quot;) curve(dnorm(x,300,sqrt(600)),lwd=2,col=&quot;red&quot;,add=TRUE) legend(&quot;topleft&quot;,col=c(&quot;black&quot;,&quot;red&quot;),lty=c(1,1), lwd=c(2,2),legend=c(&quot;Khi quadrat amb n=300&quot;,&quot;Normal&quot;),cex=0.7) Tornem un instant a això dels graus de llibertat. Per què diem que la variància (mostral) té \\(n-1\\) graus de llibertat? Doncs perquè si volem construir un conjunt de \\(n\\) nombres \\(x_1,\\ldots,x_n\\) que tenguin variància un valor donat, posem \\(y_0\\), aleshores podem escollir \\(n-1\\) d’ells, diguem \\(x_1,\\ldots,x_{n-1}\\), com volguem i aleshores el darrer, \\(x_n\\), queda bastant fixat. En matemàtiques això se sol expressar dient que tenim \\(n-1\\) graus de llibertat a l’hora d’escollir \\(x_1,\\ldots,x_n\\) amb variància fixada \\(y_0\\). En efecte, si fixam el valor \\(y_0\\geqslant 0\\) de la variància i volem trobar \\(x_1,\\ldots,x_{n}\\) tals que \\[ y_0=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}=\\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] vegem que podem triar amb total llibertat els valors de \\(x_1,\\ldots,x_{n-1}\\) i llavors el valor de \\(x_n\\) quedarà fixat per una equació quadràtica: \\[ \\begin{array}{l} ny_0 &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-n\\overline{x}^2= \\sum_{i=1}^n x_i^2-n\\Big(\\frac{\\sum_{i=1}^n x_i}{n}\\Big)^2\\\\ &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-\\frac{(\\sum_{i=1}^n x_i)^2}{n}=\\frac{1}{n}\\left(n\\sum_{i=1}^n x_i^2-\\Big(\\sum_{i=1}^{n} x_i\\Big)^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left(n\\sum_{i=1}^{n-1} x_i^2+n\\mathbf{x_n}^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 -2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}-\\mathbf{x_n}^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left((n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 \\right) \\end{array} \\] d’on obtenim, finalment, l’equació de segon grau en \\(\\mathbf{x_n}\\) \\[ (n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2-n^2y_0^2=0 \\] Per tant, fixat \\(y_0\\), podem escollir \\(x_1,\\ldots,x_{n-1}\\) com vulguem i aleshores \\(x_n\\) queda fixat com una de les dues solucions d’aquesta equació de segon grau. 1.5 La t de Student Tornem a les mitjanes mostrals de variables normals. Teorema 1.6 Sigui \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\) i sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_{X}\\). Aleshores, la variable aleatòria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] segueix una distribució coneguda, anomenada t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). A \\(\\widetilde{S}_{X}/\\sqrt{n}\\) li diem l’error típic, o estàndard, de la mostra: estima l’error estàndard \\(\\sigma_X/\\sqrt{n}\\) de \\(\\overline{X}\\). De la distribució t de Student amb \\(n\\) graus de llibertat, \\(t_{n}\\), heu de saber que: Amb R és t Si \\(T_{n}\\) és una variable amb distribució \\(t_{n}\\), aleshores \\(E(T_{n})=0\\) si \\(n\\geqslant 2\\) i \\(\\sigma_{T_{n}}^2=n/(n-2)\\) si \\(n\\geqslant 3\\) La funció de densitat d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és simètrica al voltant de 0 (com la d’una \\(N(0,1)\\)): \\[ P(T_{n}\\leqslant-x)=P(T_{n}\\geqslant x)=1-P(T_{n}\\leqslant x) \\] Si \\(n\\) és gran, la distribució d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és aproximadament la de \\(N(0,1)\\) (però amb més variància: un poc més aplatada), com podeu veure als gràfics següents: curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;Algunes t de Student&quot;) curve(dt(x,2),col=2,lwd=2,add=TRUE) curve(dt(x,3),col=3,lwd=2,add=TRUE) curve(dt(x,4),col=4,lwd=2,add=TRUE) curve(dt(x,5),col=5,lwd=2,add=TRUE) curve(dt(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:6,lty=rep(1,6), lwd=rep(2,6), legend=c(&quot;Normal estàndard&quot;, paste(&quot;Student amb g.l.=&quot;,c(2:5,10),sep=&quot;&quot;)),cex=0.7) curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;t vs Normal estàndard&quot;) curve(dt(x,50),col=2,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:2,lty=rep(1,2), lwd=rep(2,2), legend=c(&quot;Normal estàndard&quot;, &quot;Student amb g.l.=50&quot;),cex=0.7) Indicarem amb \\(t_{n,q}\\) el \\(q\\)-quantil d’una variable aleatòria \\(T_{n}\\) que segueix una distribució \\(t_n\\). És a dir, \\(t_{n,q}\\) és el valor tal que \\[ P(T_{n}\\leqslant t_{n,q})=q \\] Per la simetria de la distribució \\(t_n\\), \\[ t_{n,q}=-t_{n,1-q}. \\] Hi ha algunes propietats dels quantils de la t de Student que heu de saber: \\(t_{n ,q}\\approx z_{q}\\) si \\(n\\) és molt gran, posem \\(n \\geqslant 200\\) \\(t_{n,0.95}\\) (per a \\(n\\geqslant 10\\)) està entre 1.64 i 1.8; ho aproximarem \\(t_{n,0.95}\\approx 1.7\\) \\(t_{n,0.975}\\) (per a \\(n\\geqslant 10\\)) està entre 1.96 i 2.2; ho aproximarem \\(t_{n,0.95}\\approx 2\\) Abans de tancar aquesta secció, recordau que no heu de confondre: Desviació típica (o estàndard) d’una variable aleatòria: El paràmetre poblacional, normalment desconegut Desviació típica (o estàndard) (sigui mostral o vertadera) d’una mostra: L’estadístic que calculam sobre la mostra i que quantifica la variabilitat de la mostra Error típic (o estàndard) d’un estimador: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda Error típic (o estàndard) d’una mostra: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És la desviació típica mostral dividida per \\(\\sqrt{n}\\). 1.6 “Bons” estimadors 1.6.1 Estimadors no esbiaixats Un estimador puntual \\(\\widehat{\\theta}\\) d’un paràmetre poblacional \\(\\theta\\) és no esbiaixat quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan \\[ E(\\widehat{\\theta})=\\theta \\] Es diu aleshores que l’estimació puntual és no esbiaixada. El biaix d’un estimador \\(\\widehat{\\theta}\\) d’un paràmetre \\(\\theta\\) és la diferència \\(E(\\widehat{\\theta})-\\theta\\) Exemples: Ja hem vist a les seccions anteriors que \\(E(\\overline{X})=\\mu_X\\). Per tant, \\(\\overline{X}\\) és sempre un estimador no esbiaixat de \\(\\mu_X\\) \\(E(\\widehat{p}_X)=p_X\\). Per tant, \\(\\widehat{p}_X\\) és sempre un estimador no esbiaixat de \\(p_X\\) \\(E(\\widetilde{S}_{X}^2)=\\sigma_X^2\\) si \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}^2\\) és un estimador no esbiaixat de \\(\\sigma_X^2\\) quan \\(X\\) és normal \\(E({S}_{X}^2)=\\dfrac{n-1}{n}\\sigma_X^2\\) si \\(X\\) és normal. Per tant, en aquest cas, \\({S}_{X}^2\\) és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix \\[ E({S}_{X}^2)-\\sigma_X^2=\\dfrac{n-1}{n}\\sigma_X^2-\\sigma_X^2=-\\dfrac{\\sigma_X^2}{n}\\ \\mathop{\\longrightarrow}_{\\scriptscriptstyle n\\to\\infty}\\ 0 \\] \\(E(\\widetilde{S}_{X}), E({S}_{X})\\neq \\sigma_X\\) ni tan sols quan \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}\\) i \\({S}_{X}\\) són estimadors esbiaixats de \\(\\sigma_X\\) 1.6.2 Estimadors eficients Donats dos estimadors \\(\\widehat{\\theta}_1\\), \\(\\widehat{\\theta}_2\\) del mateix paràmetre \\(\\theta\\), direm que \\(\\widehat{\\theta}_1\\) és més eficient que \\(\\widehat{\\theta}_2\\) quan l’error típic de \\(\\widehat{\\theta}_1\\) és més petit que el de \\(\\widehat{\\theta}_2\\): \\[ \\sigma(\\widehat{\\theta}_1)&lt; \\sigma(\\widehat{\\theta}_2). \\] Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats (o, com a molt, quan el seu biaix tendeix a 0 quan \\(n\\) tendeix a \\(\\infty\\)). En aquest cas, que \\(\\widehat{\\theta}_1\\) sigui més eficient que \\(\\widehat{\\theta}_2\\) significa que la seva variabilitat és menor i que per tant les estimacions amb \\(\\widehat{\\theta}_1\\) es concentren més al voltant del seu valor esperat, que és el paràmetre \\(\\theta\\) que volem estimar, que les estimacions amb \\(\\widehat{\\theta}_2\\). Exemples: Si \\(X\\) és normal, \\(\\overline{X}\\) és l’estimador no esbiaixat més eficient de la mitjana poblacional \\(\\mu_X\\). Si \\(X\\) és Bernoulli, \\(\\widehat{p}_X\\) és l’estimador no esbiaixat més eficient de la proporció poblacional \\(p_X\\). Si \\(X\\) és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). Exemple 1.11 Sigui \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\). Considerem la mediana \\(\\mathit{Me}=Q_{0.5}\\) d’una mostra aleatòria simple de \\(X\\) com a estimador puntual de \\(\\mu_X\\), que coincideix amb la mediana de \\(X\\) per la simetria de les variables normals. Resulta que \\(E(\\mathit{Me})=\\mu_X\\) però \\[ \\sigma^2(\\mathit{Me})\\approx \\dfrac{\\pi}{2}\\cdot \\dfrac{\\sigma_{X}^2}{n}\\approx 1.57 \\cdot \\frac{\\sigma_{X}^2}{n}=1.57\\sigma^2(\\overline{X}) \\] Per tant, si \\(X\\) és normal, la mediana \\(\\mathit{Me}\\) és un estimador no esbiaixat de \\(\\mu_X\\), però menys eficient que \\(\\overline{X}\\). Per això preferim emprar la mitjana mostral per estimar \\(\\mu_X\\). Hem dit que si la població és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). La variància vertadera \\[ S_X^2=\\frac{(n-1)}{n} \\widetilde{S}_X^2 \\] és més eficient, perquè \\[ \\sigma(S_X^2)=\\sqrt{\\frac{(n-1)}{n}}\\sigma(\\widetilde{S}_X^2)&lt;\\sigma(\\widetilde{S}_X^2), \\] però és un estimador esbiaixat de \\(\\sigma_X^2\\), tot i que el seu biaix tendeix a 0 quan \\(n\\to \\infty\\). Si \\(n\\) és petit (per davall de 30), és millor fer servir la variància mostral \\(\\widetilde{S}_X^2\\) per estimar la variància, ja que el biaix pot esbiaixar el resultat, però si \\(n\\) és gran, el biaix de \\(S_X^2\\) ja és petit i es pot fer servir \\(S_X^2\\): de fet, si \\(n\\) és molt gran, dividir per \\(n\\) o per \\(n-1\\) no varia gaire el resultat i per tant \\(\\widetilde{S}_X^2\\) i \\(S_X^2\\) donen valors molt semblants. 1.6.3 Estimadors màxim versemblants Un estimador d’un paràmetre és màxim versemblant quan, aplicat a cada mostra aleatòria simple, dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra. Exemple 1.12 Suposem que tenim una variable aleatòria Bernoulli \\(X\\) de probabilitat d’èxit \\(p_X\\) desconeguda. Donada una mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), siguin \\(\\widehat{p}_x\\) la seva proporció mostral i \\(P(x_1,\\ldots,x_n\\mid p)\\) la probabilitat d’obtenir la mostra quan la probabilitat poblacional és \\(p\\). Un estimador per a \\(p_X\\) és màxim versemblant quan, aplicat a \\(x_1,\\ldots,x_n\\), ens dóna el valor de \\(p\\) que fa que \\(P(x_1,\\ldots,x_n\\mid p)\\) sigui el màxim possible. Quin creieu que és l’estimador màxim versemblant de \\(p_X\\)? Doncs sí, la proporció mostral \\(\\widehat{p}_X\\). Teorema 1.7 El valor de \\(p\\) per al qual \\(P(x_1,\\ldots,x_n\\mid p)\\) és màxim és \\(\\widehat{p}_x\\). La demostració és senzilla. Suposau que dins \\(x_1,\\ldots,x_n\\) hi ha \\(m\\) 1s i \\(n-m\\) 0s, de manera que \\(\\widehat{p}_X=m/n\\). Aleshores, la probabilitat d’obtenir \\(x_1,\\ldots,x_n\\) és \\[ P(x_1,\\ldots,x_n\\mid p)=p^m(1-p)^{n-m} \\] Per trobar el valor de \\(p\\) que fa aquest probabilitat màxima, derivau respecte de \\(p\\) i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a \\(p=m/n\\). Alguns altres estimadors màxim versemblants: \\(\\overline{X}\\) és l’estimador màxim versemblant del paràmetre \\(\\lambda\\) d’una variable aleatòria Poisson \\(\\overline{X}\\) és l’estimador màxim versemblant de la mitjana \\(\\mu\\) d’una variable aleatòria normal 1.7 Estimació de poblacions 1.7.1 Estimació de poblacions numerades Exemple 1.13 Un dia vaig voler estimar quants taxis hi havia a Palma. Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R. taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154,314,1121,823,158,940,99, 977,286,1006,1207,264,1183,1120,498,606,566,1239,860,114,701,381,836,561,494,858,187) sort(taxis) ## [1] 38 99 114 134 137 150 158 187 264 286 297 314 381 494 ## [15] 498 508 538 561 566 600 606 701 715 823 836 858 860 883 ## [29] 940 961 977 1006 1026 1120 1121 1154 1183 1207 1217 1239 Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en aquest article. La solució d’aquest problema és donada pel resultat següent: Teorema 1.8 Sigui \\(X\\) una variable aleatòria uniforme sobre \\(\\{1,2,\\ldots,N\\}\\), i sigui \\(x_1,\\ldots,x_n\\) una mostra aleatòria de \\(X\\). Sigui \\(m=\\max(x_1,\\ldots,x_n)\\). Aleshores, l’estimador no esbiaixat més eficient de \\(n\\) és \\[ \\widehat{N}=m+\\frac{m-n}{n} \\] La idea que hi ha sota aquesta fórmula és que si suposau que teniu \\(x_1,\\ldots,x_n\\) ordenats en ordre creixent, de manera que \\(x_n=m\\), i calculau la mitjana de la longitud dels ‘forats’ a l’esquerra de cada valor \\(x_i\\), tenim que a l’esquerra de \\(x_1\\) hi ha \\(x_1-1\\) nombres i entre cada \\(x_{i-1}\\) i \\(x_{i}\\) hi ha \\(x_{i}-x_{i-1}-1\\) nombres, i per tant aquesta mitjana és \\[ \\frac{(x_1-1)+(x_2-x_1-1)+\\cdots+(x_{n}-x_{n-1}-1)}{n}=\\frac{x_n-n}{n}=\\frac{m-n}{n} \\] i el que fa l’estimador \\(\\widehat{N}\\) és sumar al màxim de la mostra, \\(m\\), la mitjana dels forats entre membres de la mostra. Exemple 1.14 Continuem amb l’Exemple 1.13. Emprant la fórmula anterior, estimo que el nombre de taxis de Palma era max(taxis)+(max(taxis)-length(taxis))/length(taxis) ## [1] 1268.975 En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246. 1.7.2 Marca-recaptura Suposem que en una població hi ha \\(N\\) individus, en capturam \\(K\\) (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam \\(n\\), dels quals \\(k\\) estan marcats. A partir d’aquestes dades, volem estimar \\(N\\). Si suposam que \\(N\\) i \\(K\\) no han canviat de la primera a la segona captura, aleshores la variable aleatòria \\(X\\) definida per “Capturam un individu i miram si està marcat” és Bernoulli \\(Be(p)\\) amb \\(p=K/N\\), on coneixem la \\(K\\) volem estimar la \\(N\\). Sigui ara \\(x_1,\\ldots,x_n\\) la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és \\(\\widehat{p}_X=k/n\\). Com que \\(\\widehat{p}_X\\) és l’estimador màxim versemblant de \\(p\\), estimam que \\[ \\dfrac{K}{N}=\\dfrac{k}{n} \\] d’on, aïllant la \\(N\\), estimam que \\[ N=\\frac{n\\cdot K}{k}. \\] En resum, l’estimador \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] maximitza la probabilitat d’obtenir \\(k\\) individus marcats en una mostra aleatòria de \\(n\\) individus. És l’estimador màxim versemblant de \\(N\\) a partir de \\(K\\), \\(k\\) i \\(n\\). Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat \\(k\\) individus marcats en un conjunt de \\(n\\) individus, què ha de valer el nombre total \\(N\\) de individus perquè hi hagi en total \\(K\\) individus marcats?” Exemple 1.15 Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos estimau que conté el llac? \\[ \\widehat{N}=\\frac{15\\cdot 10}{4}=37.5 \\] Per tant, estimam que hi haurà entre 37 i 38 peixos al llac. En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població on hi ha 15 individus marcats. Per fer-ho, recordem que si una població està formada per \\(K\\) subjectes marcats i \\(N-K\\) subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida \\(n\\) segueix una distribució hipergeomètrica \\(H(K, N-K,n)\\). Per tant, per a cada possible \\(N\\), la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà dhyper(4,15,N-15,10). N=15:100 #Possibles valors de N p=dhyper(4,15,N-15,10) #Probabilitats de 4 marcats en 10 Nmax=N[which(p==max(p))] # N que maximitza la probabilitat Nmax ## [1] 37 Aquest Nmax és la \\(N\\) que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho en un gràfic: plot(N,p,type=&quot;h&quot;,xaxp=c(15,100,17)) points(Nmax,dhyper(4,15,Nmax-15,10),type=&quot;h&quot;,col=&quot;red&quot;,lwd=1.5) Un altre estimador per a \\(N\\) a partir de \\(K\\), \\(n\\) i \\(k\\) és l’estimador de Chapman: \\[ \\widehat{N}=\\frac{(n+1)\\cdot (K+1)}{k+1}-1 \\] La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador anterior i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar. En la situació de l’Exemple 1.15, aquest estimador dóna \\[ \\widehat{N}=\\frac{16\\cdot 11}{5}-1=34.2 \\] i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. Quina és la correcta? Ni idea, no ho podem saber, ja que no sabem si la proporció de peixos marcats a la segona captura reflecteix la global, o si els peixos marcats hi estan sobrerepresentats o sotarepresentats. Resulta que l’estimador màxim versemblant \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] és esbiaixat, amb biaix que tendeix a 0 quan \\(n\\) tendeix a \\(\\infty\\). L’estimador de Chapman és menys esbiaixat per a mostres petites, i no esbiaixat si \\(K+n\\geqslant N\\) (però no és màxim versemblant). "],
["intervals-de-confianca.html", "Tema 2 Intervals de confiança 2.1 Definicions bàsiques 2.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal 2.3 Interval de confiança per a la mitjana basat en la t de Student 2.4 Intervals de confiança per a proporcions 2.5 Intervals de confiança per a la variància d’una variable normal 2.6 “Poblacions finites”", " Tema 2 Intervals de confiança 2.1 Definicions bàsiques Amb un estimador, estimam el paràmetre amb una certa precisió, que depèn: De la variabilitat de la variable aleatòria d’interès De la mida de la mostra De la variabilitat de l’estimador (que segurament depèn de les dues anteriors) Del nivell de confiança, o seguretat, de l’estimació: com de segurs volem estar que l’estimació és correcta Un interval de confiança del q% (abreviadament, un IC q%) d’un paràmetre poblacional és un interval obtingut aplicant a una mostra aleatòria simple una fórmula que satisfà la propietat següent: L’interval obtingut conté el valor del paràmetre poblacional el q% de les vegades que l’aplicam sobre mostres aleatòries simples preses a l’atzar Tenir una confiança del q% significa doncs que empram una fórmula que encerta el q% de les vegades; o, per ser precisos, el q% de les vegades que l’aplicam bé. Però assumim que un (1-q)% de les vegades que l’aplicam ens equivocam, i no sabem quin és el nostre cas. Exemple 2.1 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\). Com veurem a l’Exemple 2.3, un IC 95% per al percentatge d’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa és [40.53, 41.87]. Això significa que estam segurs al 95% que l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa està entre el 40.53% i el 41.87%, perquè aquest interval l’haurem calculat amb una fórmula que el 95% de les vegades que l’aplicam (bé) dóna un interval que conté la mitjana poblacional que volem estimar. Nosaltres som optimistes i “confiam” estar dins aquest 95% d’encerts. No confongueu: Interval de referència del q% per a una variable aleatòria: Interval que conté el valor de la variable aleatòria en un individu amb probabilitat q%. Interval de confiança del q% per a un paràmetre: Interval que conté el valor poblacional del paràmetre de la variable aleatòria “amb probabilitat” q%, en el sentit que l’hem calculat amb una fórmula que dóna un interval que conté el paràmetre el q% de les vegades que l’aplicam a una mostra aleatòria. Interval de referència del q% per a un estimador: Interval que conté el valor de l’estimador sobre una mostra aleatòria amb probabilitat q%. Per exemple: Si diem que un interval de referència del 95% per a la concentració d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa significa que un 95% dels individus sans tenen una concentració d’aquesta proteïna en sèrum entre 11 i 16 g/dl, o, equivalentment, que un individu sa escollit a l’atzar té, amb un 95% de probabilitat, una concentració d’aquesta proteïna en sèrum entre 11 i 16 g/dl Si diem que un interval de confiança del 95% per a la concentració mitjana d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que hem pres una mostra aleatòria de concentracions d’aquesta proteïna en sèrum en individus sans i a partir d’aquesta mostra hem estimat que, amb un 95% de confiança, la concentració mitjana d’aquesta proteïna en sèrum en individus sans està entre 11 i 16 g/dl (i tenim un 95% de confiança en aquest interval perquè l’hem calculat amb una fórmula que dóna un interval que conté la mitjana poblacional un 95% de les vegades que l’empram). Si diem que el 95% de les mostres de 100 concentracions d’una determinada proteïna en sèrum en individus sans tenen la mitjana mostral entre 11 i 16, això és un interval de referència del 95% per a la mitjana mostral de mostres de mida 100, no un interval de confiança per a la concentració mitjana poblacional ni un interval de referència per al valor de la concentració en un individu. Que un IC q% per a un paràmetre \\(\\theta\\) sigui \\([a,b]\\) serveix: Per estimar \\(\\theta\\) amb aquest marge de confiança: Estam bastant segurs que el valor poblacional de \\(\\theta\\) està entre \\(a\\) i \\(b\\) (la fórmula emprada encerta sovint) Per poder rebutjar un valor concret de \\(\\theta\\) amb aquest marge de confiança: Estam bastant segurs que el valor real de \\(\\theta\\) no està ni per sota de \\(a\\) ni per sobre de \\(b\\) Per exemple: si un IC 95% per a la prevalència \\(p\\) d’una determinada característica en una població (la fracció d’individus que tenen aquesta característica) va de 0.025 a 0.047: Estam molt (95%) segurs que \\(p\\in [0.025,0.047]\\) (perquè la fórmula emprada per calcular aquest interval encerta en un 95% de les vegades) Estam molt segurs que \\(p&gt;0.02\\) (perquè tot l’interval on estam molt segurs que cau el valor real de \\(p\\) està a la dreta de 0.02) Estam molt segurs que \\(p\\neq 0.05\\) (perquè 0.05 no pertany a l’interval on estam molt segurs que cau el valor real de \\(p\\)) Però no estam molt segurs que \\(p=0.03\\), per molt que \\(0.03\\in [0.025,0.047]\\): estam molt segurs que \\(p\\) està entre 0.025 i 0.047, però no tenim cap seguretat que valgui un valor concret entre aquests límits, només que està entre aquests límits. Hi ha dos tipus de mètodes bàsics de càlcul d’IC a partir d’una mostra aleatòria: Paramètrics: Usant alguna fórmula basada en la distribució mostral de l’estimador Es basen en teoremes Només serveixen si la variable aleatòria \\(X\\) i la mostra aleatòria satisfan (aproximadament) les hipòtesis del teorema No paramètrics: El més emprat és el bootstrap: De la mostra, es prenen a l’atzar moltes (~1000) mostres aleatòries simples de la mateixa mida que la mostra, es calcula l’estimador amb cada una d’aquestes mostres i s’usa el vector de resultats per estimar un IC (per exemple, podríem prendre com a IC 95% l’interval entre els quantils 0.025 i 0.975 d’aquest vector) Es pot usar sempre (si la mostra és aleatòria) Empra un procés aleatori: en cada execució sobre les mateixes dades pot donar un IC diferent 2.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal Suposem que tenim una variable normal \\(X\\sim N(\\mu,\\sigma)\\). Volem trobar un IC 95% per a la seva mitjana \\(\\mu\\). Per calcular-lo, prenem una mostra aleatòria simple de mida \\(n\\), de mitjana \\(\\overline{X}\\) i variància mostral \\(\\widetilde{S}^2_X\\). Aleshores, sabem que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Si podem trobar \\(A,B\\in \\mathbb{R}\\) tals que \\[ P(A\\leqslant T\\leqslant B)=0.95, \\] llavors: \\[ \\begin{array}{rl} 0.95 &amp; =P\\Bigg(A\\leqslant\\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\overline{X}-\\mu \\leqslant B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant-\\mu \\leqslant-\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Com que \\(P(A\\leqslant T\\leqslant B)=0.95\\) significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) el valor de \\(T\\) està entre \\(A\\) i \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) la \\(\\mu\\) cau dins l’interval \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Per tant, això serà un IC 95% per a \\(\\mu\\). Ens falta trobar els \\(A,B\\) tals que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Per trobar-los, emprarem quantils de la distribució de \\(T\\). Recordem que si indicam amb \\(t_{n-1,0.975}\\) el 0.975-quantil d’una \\(t_{n-1}\\), per definició tenim que \\[ P(T\\leqslant t_{n-1,0.975})=0.975 \\] i per la simetria de la \\(t\\), \\[ P(T\\leqslant-t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025 \\] Per tant: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leqslant T\\leqslant t_{n-1,0.975})\\\\ \\quad =P(T\\leqslant t_{n-1,0.975})-P(T\\leqslant-t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Així doncs, podem prendre \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] i obtenim: Si \\(X\\sim N(\\mu,\\sigma)\\), un IC 95% per a \\(\\mu\\) és \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] L’escriurem \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Exemple 2.2 Fem un experiment per veure que, efectivament, aquesta fórmula “encerta”, en el sentit que conté la \\(\\mu\\), al voltant del 95% de les vegades. Al bloc de codi següent: generam una Població de 107 “individus” que segueixen una llei normal estàndard i en calculam la mitjana mu; definim una funció IC que calcula l’IC 95% per a la mitjana \\(\\mu\\) amb la fórmula anterior; prenem 200 mostres aleatòries simples de mida 50 de la nostra població i les aplicam aquesta funció, obtenint una matriu M de 200 columnes formades pels dos extrems dels intervals (l’inferior a la primera filera i el superior a la segona filera); finalment, miram quantes vegades hem encertat, és a dir, a quantes columnes de M la mitjana poblacional mu està entre l’entrada de la primera filera i la de la segona. set.seed(42) Poblacio=rnorm(10^7) mu=mean(Poblacio) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Poblacio,50,replace=TRUE))) Encerts=length(which(mu&gt;=M[1,] &amp; mu&lt;=M[2,])) Encerts ## [1] 189 Hem encertat 189 vegades, és a dir, un 94.5% de les vegades. És aproximadament el que esperàvem. Si ho provau amb altres llavors d’aleatorietat obtendreu altres resultats, de vegades millors, de vegades pitjors. Per veure millor els encerts, dibuixam els intervals en un gràfic, on apareixeran en gris els que encerten i en vermell els que no encerten. plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valors&quot;,ylab=&quot;Repeticions&quot;, main=&quot;200 IC 95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Atenció! De mitjana, un IC q% NO conté el valor real del paràmetre en un (100-q)% de les ocasions. Per exemple, de mitjana, un 5% de les vegades que calculam un IC 95%, el paràmetre poblacional no pertany a l’interval obtingut. Per tant, si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, el nombre de vegades que l’interval resultant no contendrà el paràmetre poblacional seguirà una distribució binomial \\(B(n,0.05)\\). El gràfic següent dóna el valor de \\(P(X\\geqslant 1)\\) per a una variable aleatòria \\(X\\) de tipus \\(B(n,0.05)\\), per a \\(n=0,...,100\\), i per tant la probabilitat que si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, almenys un d’ells no contengui el paràmetre poblacional desitjat. plot(1-dbinom(0,0:100,0.05),pch=20,xlab=&quot;n&quot;,ylab=&quot;Probabilitat&quot;, main=&quot;Probabilitat d&#39;algun èxit en una B(n,0.05)&quot;) Tornant a l’IC 95% per a \\(\\mu\\) d’una variable normal donat per la fórmula \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] fixau-vos que: Està centrat en \\(\\overline{X}\\), per tant en cada càlcul estarà centrat en la mitjana mostral Tal i com l’hem calculat, la probabilitat que \\(\\mu\\) caigui fora d’aquest interval es reparteix per igual als dos costats: un 2.5% de les vegades la \\(\\mu\\) poblacional estarà a l’esquerra de l’extrem inferior i un 2.5% de les vegades estarà a la dreta de l’extrem superior Exemple 2.3 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1 \\] Per calcular un IC 95% per al percentatge mitjà d’augment, suposarem que la mostra és aleatòria simple i que la variable aleatòria que dóna el percentatge d’augment d’alcohol en sang en una persona després de prendre 4 canyes de cervesa és normal. Llavors, com que \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC 95% és \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Hem suposat que la variable poblacional “Percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” segueix una distribució normal. I si no fos normal? En aquest cas, com que \\(n=40\\), és gran pel Teorema 2.2 de la propera secció l’interval obtingut segueix essent (aproximadament) un interval de confiança del 95% per a \\(\\mu\\) Si \\(n\\) fos petit i \\(X\\) molt diferent d’una normal, no es pot usar aquesta fórmula i cal buscar-se la vida (per exemple, emprar el mètode de bootstrap) 2.3 Interval de confiança per a la mitjana basat en la t de Student A partir d’ara, per tal d’evitar ambigüitats, a les fórmules expressarem el nivell de confiança dels intervals en tant per u, no en tant per cent, i parlarem d’intervals de confiança de nivell de confiança \\(q\\), amb \\(q\\) entre 0 i 1, en lloc d’intervals de confiança del \\(100q\\%\\). És a dir, per exemple, els intervals de confiança del 95% seran intervals de confiança de nivell de confiança 0.95. La fórmula El mateix argument que abans, canviant 0.95 per \\(q\\) dóna: Teorema 2.1 Si \\(X\\sim N(\\mu,\\sigma)\\) i prenem una mostra aleatòria simple de mida \\(n\\), un IC de nivell de confiança \\(q\\) (en tant per u) per a \\(\\mu\\) és \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que als IC 95%, \\(q=0.95\\) i per tant \\((1+q)/2=1.95/2=0.975\\). Usant el Teorema Central del Límit i algunes aproximacions, tenim el següent resultat: Teorema 2.2 Sigui \\(X\\) una variable aleatòria qualsevol de mitjana poblacional \\(\\mu\\). Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (diguem, de 40 o més elements). Llavors, un IC de nivell de confiança \\(q\\) per a \\(\\mu\\) és aproximadament \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] L’aproximació del teorema anterior és millor com més gran sigui \\(n\\) o com més propera a una normal sigui la variable poblacional \\(X\\). En resum: Podem emprar la fórmula per a l’IC de nivell de confiança \\(q\\) per a la mitjana poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] quan la variable poblacional és normal o quan la mostra aleatòria simple és gran. Exemple 2.4 L’empresa RX-print ofereix una impressora de radiografies d’altíssima qualitat. En la seva publicitat afirma que els seus cartutxos imprimeixen una mitjana de 500 radiografies amb l’especificació: Dades tècniques: Mostra de mida \\(n=25\\), població suposada normal, nivell de confiança del 90% Uns radiòlegs desitgen comprovar aquestes afirmacions i prenen una mostra de cartutxos a l’atzar de mida \\(n=25\\), obtenint una mitjana de \\(\\overline{x}=518\\) radiografies i una desviació típica mostral \\(\\widetilde{s}=39.9\\). Amb aquesta mostra, la mitjana poblacional anunciada pel fabricant cau dins l’interval de confiança del 90%? La variable aleatòria d’interès és \\(X\\) és “Prenem un cartutxo d’aquesta empresa i miram el nombre de radiografies que permet imprimir”, de mitjana \\(\\mu\\) per a la qual volem calcular un IC 90%. Suposarem que la variable \\(X\\) és normal, perquè l’empresa ho suposa a les dades tècniques. Per tant podem emprar la fórmula \\[ \\overline{x}\\pm t_{n-1,(q+1)/2} \\frac{\\widetilde{s}}{\\sqrt{n}} \\] on \\(n=25\\), \\(\\overline{x}=518\\), \\(\\widetilde{s}=39.9\\), \\(q=0.9\\), \\((q+1)/2=0.95\\) i \\(t_{24,0.95}\\)=qt(0.95,24)\\(=1.71\\). Operant: \\[ 518\\pm 1.71\\times \\frac{39.9}{\\sqrt{25}}\\Rightarrow 518\\pm 13.65\\Rightarrow [504.35,531.65] \\] No conté el 500 (en benefici del consumidor: tenim un 95% de seguretat que el nombre mitjà de radiografies per cartutxo està en realitat entre 504.35 i 531.65). Exemple 2.5 A l’exemple anterior hem suposat que la variable aleatòria era normal. Què passaria si no ho fos? Com que \\(n=25\\) no és prou gran, no podríem aplicar la fórmula de l’IC basada en la t de Student. Emprarem el mètode del bootstrap, per a la qual cosa necessitam tenir les dades originals, i no només els seus estadístics. Tenim aquestes dades en el vector Radios següent: Radios=c(485,511,509,509,561,529,458,532,545,546, 503,577,547,477,507,548,480,444,461,573, 513,604,542,501,488) mean(Radios) ## [1] 518 sd(Radios) ## [1] 39.89987 Prenem 5000 mostres aleatòries simples de mida 25 (la mateixa mida que el conjunt de dades original) de les dades i calculam la mitjana de cada mostra; fixam la llavor d’aleatorietat perquè el càlcul sigui reproduïble: set.seed(100) Simulacions=replicate(5000,mean(sample(Radios,25,rep=TRUE))) Ara prenem com a IC 90% l’interval que va del quantil 0.05 al quantil 0.95 d’aquest vector de mitjanes: quantile(Simulacions,c(0.05,0.95)) ## 5% 95% ## 504.96 530.92 Obtenim l’interval [504.96,530.92]: amb la fórmula basada en la t de Student, havíem obtingut l’interval [504.35,531.65]. Algunes consideracions Observau que l’estructura de l’IC de nivell de confiança \\(q\\) per a \\(\\mu\\) donat al Teorema 2.2 \\[\\begin{align} &amp; \\text{estimador}\\nonumber\\\\ &amp; \\qquad \\pm \\frac{1+q}{2}\\text{-quantil de la distr. mostral}\\times \\text{error típic de l&#39;estimació} \\tag{2.1} \\end{align}\\] Aquesta estructura és molt típica (però, com veurem, no tots els IC paramètrics tenen aquesta forma) i satisfà que: L’IC està centrat en el valor de l’estimador La “probabilitat d’equivocar-se” es reparteix per igual als dos costats de l’interval: una fracció \\(q/2\\) de les vegades el paràmetre estarà a l’esquerra de l’extrem inferior i una fracció \\(q/2\\) de les vegades estarà a la dreta de l’extrem superior A més, tenim que: Per a una mateixa mostra i una mateixa fórmula (paramètrica) per calcular l’IC, si el nivell de confiança creix, l’IC s’eixampla Això és general, per a tots els intervals de confiança paramètrics. La idea intuitiva és que, per estar més segurs que un interval conté un valor, l’interval ha de ser més ample. A un IC amb l’estructura (2.1), el motiu matemàtic és que si \\(q\\) creix, el quantil (1+\\(q\\))/2 de la distribució mostral creix. Per exemple, a l’Exemple 2.3, teníem \\(n=40\\), \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\): L’IC 95% té \\(q=0.95\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), i donava \\[ IC:\\ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] L’IC 99% té \\(q=0.99\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), i dóna \\[ IC:\\ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] més ample Però si canviam de mostra (o de fórmula, si n’hi ha més d’una) per calcular l’IC, pot passar qualsevol cosa. Amb R La funció t.test(X,conf.level=...)$conf.int calcula l’interval de confiança basat en la t de Student per a la \\(\\mu\\) de la variable aleatòria de la que el vector X n’és una mostra. El paràmetre conf.level permet especificar el nivell de confiança (en tant per u). El seu valor per defecte és 0.95, així que per calcular un IC 95% no cal especificar-lo. Per exemple, l’IC 90% del vector de nombres de radiografies de l’Exemple 2.4 es calcularia amb t.test(Radios,conf.level=0.9)$conf.int ## [1] 504.3472 531.6528 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 Càlcul de la mida de la mostra per fixar l’error Recordem que l’IC q% per a \\(\\mu\\) basat en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] és simètric i centrat en \\(\\overline{X}\\). La seva amplada és la diferència entre els seus extrems \\[ 2t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] El marge d’error (error, precisió) \\(M\\) en l’estimació de \\(\\mu\\) per mitjà d’aquest IC é el que sumam i restam a \\(\\overline{X}\\) per obtenir l’interval, és a dir, la meitat de la seva amplada: \\[ M=t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Una pregunta típica a l’hora de planejar un experiment és quina ha de ser la mida de la mostra que hem de prendre perquè el marge d’error sigui com a màxim un cert valor desitjat \\(M_{max}\\). És a dir, volem trobar la \\(n\\) més petita tal que \\[ t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant M_{max}. \\] Però fixau-vos que en aquesta desigualtat la \\(n\\) hi apareix al quantil i a l’error típic, i a més la \\(\\widetilde{S}_X\\) depèn de la mostra. El que farem per respondre la pregunta serà fer algunes trampes: Aproximarem la t de Student per una normal estàndard (ja que segurament la \\(n\\) haurà de ser gran): \\[ t_{n-1,(1+q)/2}\\rightsquigarrow z_{(1+q)/2} \\] Estimarem el valor de \\(\\widetilde{S}_X\\) mitjançant la desviació típica mostral \\(\\widetilde{S}_0\\) d’una prova pilot (una experiment anterior, realitzat per nosaltres o per qualcú altre amb una mostra petita) D’aquesta manera, aproximam l’error \\(M\\) per mitjà de \\[ M\\approx z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}} \\] I ara si imposam que \\(M\\leqslant M_{max}\\), ja podem aïllar la \\(n\\): \\[ z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}}\\leqslant M_{max}\\Longrightarrow n\\geqslant\\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2 \\] En resum: Teorema 2.3 Per estimar la \\(\\mu\\) amb nivell de confiança \\(q\\) amb un marge d’error com a màxim \\(M_{max}\\) mitjançant la fórmula basada en la t de Student, prendrem una mostra de mida \\(n \\geqslant( z_{(1+q)/2}\\cdot \\widetilde{S}_0/M_{max})^2\\), on \\(\\widetilde{S}_0\\) és la desviació típica mostral obtinguda en una estimació anterior de \\(\\mu\\) (en una prova pilot). Naturalment, quan després prenguem una mostra de mida \\(n\\) calculada d’aquesta manera, pot passar qualsevol cosa, ja que hem emprat els resultats d’una mostra aleatòria per estimar la desviació típica d’una altra mostra i a més hem aproximat els quantils de la t de Student per els d’una normal estàndard, que són més petits. Però almenys haurem fet tot el que haurem pogut per fitar l’error dins el marge desitjat. Exemple 2.6 A l’Exemple 2.3, hem emprat una mostra de \\(n=40\\) persones, amb \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\), i l’error ha estat \\[ t_{0.975,39}\\cdot \\frac{2.1}{\\sqrt{40}}=0.67 \\] Quin és el nombre mínim de persones que hauríem hagut d’emprar per obtenir un IC 95% amb un error de (com màxim) 0.5? Empram l’exemple com a prova pilot: \\[ n\\geqslant\\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{s}}{M_{max}} \\right)^2= \\left(\\frac{1.96\\cdot 2.1}{0.5} \\right)^2=67.77 \\] El valor de \\(n\\) més petit que satisfà aquesta condició és 68, per tant aquest és el nombre mínim de persones que hauríem hagut d’emprar per esperar obtenir un IC 95% amb un error de (com màxim) 0.5. 2.4 Intervals de confiança per a proporcions Suposem que tenim una variable Bernoulli \\(X\\) amb probabilitat d’èxit \\(p_X\\) desconeguda. Volem calcular un IC per a \\(p_X\\). Per fer-ho, prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\), amb nombre d’èxits \\(x\\) i per tant proporció mostral d’èxits \\(\\widehat{p}_{X}=x/n\\) Explicarem tres mètodes per calcular aquest IC: El mètode exacte de Clopper-Pearson, que es pot aplicar sempre però sol donar intervals de confiança més amples del necessari. El mètode aproximat de Wilson, que es pot emprar quan la mostra és gran, posem de mida 40 o més, i es basa en el fet que, pel Teorema Central del Límit, la proporció mostral de mostres aleatòries simples segueix una distribució aproximadament normal. El mètode aproximat de Laplace, que és una simplificació del mètode de Wilson, però només es pot emprar quan la mostra és bastant més gran, posem de mida 100 o més, i la proporció mostral \\(\\widehat{p}_{X}\\) no és molt propera a 0 o a 1. És el mètode més clàssic i conegut. Mètode “exacte” de Clopper-Pearson Aquest mètode es basa en el fet que el nombre d’èxits \\(x\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial \\(B(n,p_X)\\). Raonant de manera similar a com obteníem l’interval per a \\(\\mu\\) basat en la t de Student (us estalviarem els detalls) arribam a la fórmula següent: Teorema 2.4 Un IC de nivell de confiança \\(q\\) per a \\(p_X\\) és \\([p_0,p_1]\\), on \\(p_0\\) és la solució de l’equació \\[ \\sum_{k=x}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}= \\frac{1-q}{2} \\] \\(p_1\\) és la solució de l’equació \\[ \\sum_{k=0}^x\\binom{n}{k}p_1^k(1-p_1)^{n-k}= \\frac{1-q}{2} \\] Calcular a mà aquest interval és intractable, i en general dóna més ample del necessari (degut a la natura discreta de la distribució binomial, que només pren valors nombres naturals), però es pot emprar amb mostres aleatòries simples de qualsevol mida ja que empra que el nombre d’èxits \\(x\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial i això sempre és veritat. Per calcular-lo amb R, podeu emprar la funció del paquet epitools binom.exact(x,n,conf.level=...) on xés el nombre d’èxits, n la mida de la mostra, i conf.level el nivell de confiança en tant per u, que per defecte val 0.95. Exemple 2.7 De 10 pacients tractats amb un medicament, 2 s’han curat. Quin seria un IC 95% per a la proporció p de pacients que aquest medicament cura? Emprarem el mètode de Clopper-Pearson library(epitools) round(binom.exact(2,10),3) ## x n proportion lower upper conf.level ## 1 2 10 0.2 0.025 0.556 0.95 Dóna [0.025,0.556]. L’interval de Clopper-Pearson té l’inconvenient que,en general, no està centrat en \\(\\widehat{p}_{X}\\). Per exemple, el centre de l’interval anterior és \\((0.025+0.556)/2= 0.29\\), diferent de \\(\\widehat{p}_X=0.2\\) Mètode de Wilson Suposem ara que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (posem, de 40 o més subjectes) i proporció mostral d’èxits \\(\\widehat{p}_{X}\\). En aquestes condicions, pel Teorema Central del Límit, \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\approx N(0,1) \\] Per tant \\[ P\\Big(-z_{(1+q)/2}\\leqslant\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leqslant z_{(1+q)/2}\\Big)=q \\] Aïllant \\(p_X\\) obtenim: Teorema 2.5 Si la mida \\(n\\) de la mostra és gran, un IC de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}\\pm z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Amb R es calcula amb la funció binom.wilson(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquest interval també té l’inconvenient que, si us hi fixau, no està centrat en \\(\\widehat{p}_{X}\\): el seu centre és \\(\\big(\\widehat{p}_{X}+z_{(1+q)/{2}}^2/(2n)\\big)/(1+z_{(1+q)/{2}}^2/{n})\\). Mètode de Laplace Suposem finalment que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) més gran i \\(\\widehat{p}_{X}\\) enfora de 0 i 1. Per fixar idees, suposem que \\[ n\\geqslant 100,\\ n\\widehat{p}_{X}\\geqslant 10,\\ n(1-\\widehat{p}_{X})\\geqslant 10 \\] En aquest cas, a la fórmula de l’interval de Wilson podem suposar que els termes \\(z_{(1+q)/{2}}^2/n\\) són (aproximadament) 0 i obtenim la fórmula següent: Teorema 2.6 En les condicions explicades, un IC de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Amb R es calcula amb la funció binom.approx(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquesta fórmula és la més popular, amb més de 200 anys de rodatge. Us heu de saber la fórmula de Laplace, no cal saber les fórmules dels altres dos intervals. Més exemples Exemple 2.8 En una mostra aleatòria de 500 famílies amb nins en edat escolar es va trobar que 340 introduïen fruita de forma diària en la dieta dels seus fills. A partir d’aquestes dades, volem calcular un interval de confiança del 95% per a la proporció real de famílies d’aquesta ciutat amb nins en edat escolar que incorporen fruita fresca de forma diària en la dieta dels seus fills. Diguem \\(X\\) a la variable aleatòria “Prenem una família amb nins en edat escolar i miram si inclou diàriament fruita a la dieta dels fills”. És Bernoulli, digem \\(p_X\\) a la seva probabilitat d’èxit: la probabilitat que una família amb nins en edat escolar inclogui diàriament fruita a la dieta dels fills. Cercam un interval de confiança del 95% per a \\(p_X\\) Com que \\(n=500\\geqslant 100\\), \\(n\\widehat{p}_X=340\\geqslant 10\\) i \\(n(1-\\widehat{p}_X)=160\\geqslant 10\\), podem emprar la fórmula de Laplace \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] amb \\(n=500\\), \\(\\widehat{p}_{X}=340/500=0.68\\) i \\(z_{(q+1)/2}=z_{0.975}=1.96\\). Dóna \\[ 0.68\\pm 1.96\\sqrt{\\frac{0.68(1-0.68)}{500}}\\Rightarrow [0.639,0.721] \\] Amb R: round(binom.approx(340,500), 3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.639 0.721 0.95 Amb els altres mètodes, que també podríem aplicar en aquest cas, obtenim els intervals: round(binom.exact(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637 0.721 0.95 round(binom.wilson(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.638 0.719 0.95 Quan podem calcular més d’un interval per a \\(p_X\\), quin calculam? D’entrada cal dir que si podem calcular més d’un interval, segurament donaran molt parescuts, com heu pogut comprovar a l’exemple anterior. Però en tot cas, si podeu triar, heu de tenir en compte que: L’interval de Clopper-Pearson és exacte, no empra cap aproximació, però: Tendeix a donar un interval més ample del necessari No està centrat en la proporció mostral Només és un interval “exacte” si la mostra és aleatòria simple, cosa que gairebé sempre serà fals (com a molt, serà “aproximadament” aleatòria simple) Com que fins fa poc no es podia calcular, no és molt popular L’interval de Wilson és aproximat, fa servir l’aproximació a la normal donada pel Teorema Central del Límit. Això no és un gran emperò, pequè tanmateix segurament la mostra serà com a molt “aproximadament” aleatòria simple. Ara bé, tampoc no està centrat en la proporció mostral L’interval de Laplace és molt aproximat, però: Forma part de la cultura general del científic, tothom el coneix És l’únic centrat en la proporció mostral Exemple 2.9 En un assaig d’un nou tractament de quimioteràpia, en una mostra de \\(n\\) malalts tractats, cap desenvolupà càncer testicular com a efecte secundari. Quin seria un interval de confiança al 95% per a la proporció de malalts tractats amb aquesta quimio que desenvolupen càncer testicular? Per calcular-lo podem emprar el mètode de Clopper-Pearson, i si \\(n\\) és gran, podem emprar el mètode de Wilson. No podem emprar la fórmula de Laplace, perquè \\(\\widehat{p}_X=0\\). Pel que fa a Clopper-Pearson, aquest és un dels pocs casos que admeten solució analítica senzilla: dóna l’interval \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] Per exemple, si \\(n=40\\) binom.exact(0,30) ## x n proportion lower upper conf.level ## 1 0 30 0 0 0.1157033 0.95 1-0.025^(1/30) ## [1] 0.1157033 Si podem emprar el mètode de Wilson, la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(q+1)/2}^2}{2n}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(q+1)/2}^2}{4n^2}}}{1+\\frac{z_{(q+1)/2}^2}{n}} \\] amb \\(\\widehat{p}_{X}=0\\) i \\(z_{(1+q)/2}=1.96\\) dóna \\[ \\frac{\\frac{1.96^2}{2n}\\pm 1.96\\sqrt{\\frac{1.96^2}{4n^2}}}{1+\\frac{1.96^2}{n}}\\Longrightarrow \\Big[0,\\frac{1.96^2}{n+1.96^2}\\Big]=\\Big[0,\\frac{3.84}{n+3.84}\\Big] \\] Per exemple, un altre cop amb \\(n=40\\) binom.wilson(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 6.330897e-18 0.0876216 0.95 qnorm(0.975)^2/(40+qnorm(0.975)^2) ## [1] 0.0876216 Quan s’ha de calcular un interval de confiança del 95% per a una probabilitat \\(p_X\\) a partir d’una mostra aleatòria simple on no hi ha hagut cap èxit, sovint es fa servir la regla següent: Regla del 3: Quan en una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli de paràmetre \\(p_X\\) no hi trobam cap èxit, un IC 95% per a \\(p_X\\) va, aproximadament, de 0 a \\(3/n\\). Amb aquesta regla, en el nostre exemple amb \\(n=40\\) obtendríem l’interval [0,3/40]=[0,0.075], no molt enfora del [0,0.088] que hem obtingut amb els altres dos mètodes. Per veure com la regla del 3 aproxima l’interval de Clopper-Pearson, el gràfic següent mostra els valors \\(3/n\\) i l’extrem superior de l’IC 95% de Clopper-Pearson a partir d’una mostra de mida \\(n\\) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.7,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,lty=c(NA,1),pch=c(20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;red&quot;),cex=0.7) El gràfic següent mostra els valors \\(3/n\\) i els extrems superiors dels IC 95% de Clopper-Pearson i de Wilson a partir d’una mostra de mida \\(n\\) (\\(n\\geqslant 40\\) per als IC de Wilson) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.5,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=1.5,add=TRUE) points(40:100,3.84/(40:100+3.84),pch=20,cex=0.5,col=&quot;blue&quot;) legend(&quot;topright&quot;,lty=c(NA,NA,1),pch=c(20,20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Wilson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;blue&quot;,&quot;red&quot;),cex=0.7) Els extrems superiors dels intervals de Clopper-Pearson i Wilson se superposen. Exemple 2.10 En un assaig d’un tractament de quimioteràpia, en una mostra de 100 pacients tractats, 25 desenvoluparen càncer testicular secundari. Volem calcular un IC 95% per a la proporció de pacients tractats amb aquesta quimioteràpia que desenvolupen càncer testicular. En aquest cas podem emprar els tres mètodes: round(binom.exact(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1688 0.3466 0.95 round(binom.wilson(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1755 0.343 0.95 round(binom.approx(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651 0.3349 0.95 Càlcul de la mida de la mostra per a fixar l’error L’error de l’interval de confiança de Laplace és \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] No podem determinar la mida de la mostra a fi que l’interval de confiança tingui un error màxim sense conèixer \\(\\widehat{p}_{X}\\), que no coneixem sense una mostra. Però en el cas de l’interval de Laplace per a una proporció, podem donar un \\(n\\) que garanteixi una amplada màxima donada valgui el que valgui \\(\\widehat{p}_{X}\\in [0,1]\\). Fixau-vos que la funció \\(y=p (1-p)\\), amb \\(p\\in [0,1]\\), és una paràbola còncava amb vèrtex al punt \\(p=0.5\\) curve(x*(1-x),xlim=c(0,1),xlab=&quot;p&quot;,ylab=&quot;&quot;) abline(v=0.5,lty=&quot;dashed&quot;) Per tant, el seu màxim s’assoleix a \\(p=0.5\\). Així, doncs \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2\\text{ per a tot $\\widehat{p}_X\\in[0,1]$} \\] i per tant \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] D’aquesta manera, si \\(n\\) és tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max} \\] aleshores \\(M\\leqslant M_{max}\\) segur, valgui el que valgui \\(\\widehat{p}_{X}\\). Per tant, el que farem serà calcular la \\(n\\) per obtenir un error com a màxim \\(M_{max}\\) en el cas més desfavorable: quan l’interval és el més ample possible, és a dir, suposant que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geqslant\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geqslant\\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2 \\] En resum: Teorema 2.7 Si \\(n\\geqslant\\big(z_{(q+1)/2}/(2\\cdot M_{max})\\big)^2\\), l’error de l’interval de Laplace calculat amb una mostra de mida \\(n\\) sempre serà com a molt \\(M_{max}\\). Exemple 2.11 Quina és la mida més petita d’una mostra que ens garanteixi un error de com a màxim 0.05 en estimar una proporció \\(p_X\\) emprant un interval de confiança de Laplace del 95%? Pel teorema anterior, per garantir un error de 0.05 en calcular un IC 95% per una proporció \\(p_X\\) emprant la fórmula de Laplace, hem d’emprar una mostra de mida \\(n\\) tal que \\[ n\\geqslant\\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] La mida més petita que satisfà aquesta condició és \\(n=385\\). Observau tres coses: El valor de \\(n\\) només depèn de la precisió i del nivell de confiança, no de la natura de l’estudi Tal i com hem trobat la \\(n\\), estam segurs que si la mostra és com a mínim d’aquesta mida, l’interval de confiança de Laplace tendrà com a màxim una amplada \\(2M_{max}\\), sigui quina sigui la mostra. És de les poques vegades que podem estar segurs de qualque cosa en estadística. El teorema anterio és per l’amplada de l’interval de Laplace, però la \\(n\\) segurament us sortirà molt gran i en aquest cas l’interval de Laplace sol aproximar molt bé els altres dos intervals. 2.5 Intervals de confiança per a la variància d’una variable normal Suposem que tenim una variable normal \\(X\\sim N(\\mu,\\sigma)\\). Volem trobar un IC 95% per a la seva variància \\(\\sigma^2\\) (o la seva desviació típica \\(\\sigma\\)). Per calcular-lo, prenem una mostra aleatòria simple de mida \\(n\\), de variància mostral \\(\\widetilde{S}^2_X\\). Recordau que, en aquestes condicions \\[ \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2} \\] té distribució \\(\\chi^2_{n-1}\\) Podem aprofitar aquest fet per obtenir intervals de confiança per a \\(\\sigma^2\\): Teorema 2.8 Si la variable \\(X\\) és normal, un IC de nivell de confiança \\(q\\) per a \\(\\sigma^2\\) és \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right], \\] on \\(\\chi_{n-1,r}^2\\) és el \\(r\\)-quantil de la distribució \\(\\chi_{n-1}^2\\) La justificació d’aquesta fórmula és la usual: com que \\[ \\begin{array}{l} \\displaystyle P(\\chi_{n-1}^2\\leqslant\\chi_{n-1,(1-q)/2}^2)=\\frac{1-q}{2}\\\\ \\displaystyle P(\\chi_{n-1}^2\\geqslant\\chi_{n-1,(1+q)/2}^2)=\\frac{1-q}{2}, \\end{array} \\] tenim que \\[ \\begin{array}{l} q=P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant\\chi_{n-1}^2\\leqslant \\chi_{n-1,(1+q)/2}^2\\right)\\\\[2ex] \\quad\\displaystyle =P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant\\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2}\\leqslant \\chi_{n-1,(1+q)/2}^2 \\right)\\\\[2ex] \\quad\\displaystyle = P\\left(\\frac{(n-1) \\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}\\leqslant\\sigma^2\\leqslant\\frac{ (n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right) \\end{array} \\] Fixau-vos que aquest interval de confiança per \\(\\sigma^2\\) no està centrat en \\(\\widetilde{S}_{X}^2\\). A més, com que \\(\\chi_{n-1}^2\\) no és simètrica, s’han de calcularels dos quantils \\(\\chi_{n-1,(1-q)/2}^2\\) i \\(\\chi_{n-1,(1+q)/2}^2\\) Exemple 2.12 Un índex de qualitat d’un reactiu químic és el temps que triga a actuar. L’estàndard és que aquest ha de ser \\(\\leqslant 30\\) segons. Se suposa que la distribució del temps d’actuació del reactiu és aproximadament normal. Es realitzen 30 proves en les quals es mesura el temps d’actuació del reactiu. Tenim els resultats guardats en el vector següent: Temps=c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19,25,25,26,27,30,33,34,35,40,40,51,51,58,59,83) Volem calcular un interval de confiança per a la desviació típica \\(\\sigma\\) d’aquest temps d’actuació, amb nivell de confiança 95%. Com que la variable que ens dóna el temps és (aproximadament) normal, podem emprar la fórmula per a l’IC del 95% per a \\(\\sigma^2\\) anterior: \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right] \\] on: \\(n=\\)length(Temps)\\(=30\\) \\(\\widetilde{S}_X^2=\\)var(Temps)\\(=301.5505747\\) \\(q=0.95\\), per tant \\(\\chi_{n-1,(1+q)/2}^2=\\)qchisq(0.975,29)\\(=45.7222858\\) i \\(\\chi_{n-1,(1-q)/2}^2=\\)qchisq(0.025,29)\\(=16.0470717\\) Obtenim l’interval: \\[ \\left[ \\frac{29\\cdot 301.55}{45.72}, \\frac{29\\cdot 301.55}{16.05}\\right]= [191.26, 544.96] \\] Però aquest interval és per a la variància. Per obtenir un IC per a la desviació típica, prenem arrels quadrades dels extrems: \\[ [\\sqrt{191.26}, \\sqrt{544.96}]=[13.83,23.34] \\] L’interval per a la variància basat en la distribució \\(\\chi^2\\) no és vàlid si la variable poblacional no és (aproximadament) normal. En aquest cas, el millor és emprar un mètode no paramètric, com per exemple el bootstrap. 2.6 “Poblacions finites” Fins ara hem emprat mostres aleatòries simples. Què passa si prenem mostres aleatòries sense reposició? Si la mida \\(N\\) de la població és molt més gran que la mida \\(n\\) de la mostra (posem \\(N\\geqslant 1000n\\)), les fórmules donades fins ara funcionen (aproximadament) bé. Quan la mida \\(N\\) de la població no és molt més gran que la mida \\(n\\) de la mostra, el que es fa és, a les fórmules que hem donat per als intervals de confiança per a \\(\\mu\\) o \\(p_X\\), multiplicar-hi l’error estàndard pel factor de població finita \\[ \\sqrt{\\frac{N-n}{N-1}} \\] Així: Si \\(X\\) és una població de mida \\(N\\) amb mitjana poblacional \\(\\mu\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\), i si \\(X\\) normal o si \\(n\\) és gran, es recomana prendre com a IC de nivell de confiança \\(q\\) per a \\(\\mu\\) \\[ \\overline{X}\\pm t_{n,(q+1)/2}\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Si \\(X\\) una població de mida \\(N\\) que segueix una distribució Bernoulli amb probabilitat d’èxit \\(p_X\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb \\(n\\) molt gran i nombres d’èxits i fracassos com a mínim 10, es recomana prendre com a IC de nivell de confiança \\(q\\) per a \\(p_X\\) \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En les condicions del punt anterior, per obtenir un IC de nivell de confiança \\(q\\) per a \\(p_X\\) amb un marge d’error \\(M_{max}\\) en el cas més desfavorable caldrà prendre una mostra de mida \\[ n\\geqslant\\frac{Nz_{(q+1)/2}^2}{4M_{max}^2(N-1)+z_{(q+1)/2}^2} \\] Exemple 2.13 En una mostra aleatòria de 727 estudiants (diferents) de la UIB (\\(N=12000\\)), 557 afirmàrem haver comès plagi en algun treball durant els seus estudis. Quin seria un interval de confiança del 95% per a la proporció \\(p_X\\) d’estudiants de la UIB que han comès plagi en algun treball? Una mostra de 727 estudiants diferents és molt gran respecte del total d’estudiants de la UIB, per la qual cosa convé emprar la fórmula de Laplace amb el factor de població finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] on \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) i \\(N=12000\\): dóna \\[ 0.766\\pm \\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.751,0.781] \\] Estimam amb un nivell de confiança del 95% que entre un 75.1 i un 78.1 dels estudiants de la UIB han comès plagi en algun treball. Exemple 2.14 De quina mida hem de prendre una mostra aleatòria sense reposició d’estudiants de la UIB per estimar una proporció amb nivell de confiança del 95% i un marge d’error màxim de 0.05? Per la fórmula anterior (prenent \\(N=12000\\) i \\(z_{(1+q)/2}=1.96\\)), per garantir un marge d’error màxim de 0.05 cal prendre una mostra de mida \\[ n\\geqslant\\frac{12000\\cdot 1.96^2}{4\\cdot 0.05^2(12000-1)+1.96^2}=372.3 \\] Per tant, ens calen 373 estudiants. "]
]
